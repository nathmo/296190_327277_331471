{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f23e1c5",
   "metadata": {},
   "source": [
    "# [IAPR][iapr]: Final project - Chocolate Recognition\n",
    "\n",
    "\n",
    "**Moodle group ID:** *3*\n",
    "**Kaggle challenge:** *Deep learning*\n",
    "**Kaggle team name (exact):** \"*Byte the Bar*\"\n",
    "\n",
    "**Author 1 (sciper):** Nathann Morand (296190)\n",
    "\n",
    "**Author 2 (sciper):** David Croce (327277)\n",
    "\n",
    "**Author 3 (sciper):** Felipe Ramirez (331471)\n",
    "\n",
    "**Due date:** 21.05.2025 (11:59 pm)\n",
    "\n",
    "\n",
    "## Key Submission Guidelines:\n",
    "- **Before submitting your notebook, <span style=\"color:red;\">rerun</span> it from scratch!** Go to: `Kernel` > `Restart & Run All`\n",
    "- **Only groups of three will be accepted**, except in exceptional circumstances.\n",
    "\n",
    "\n",
    "[iapr]: https://github.com/LTS5/iapr2025\n",
    "\n",
    "---"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Introduction\n",
    "We are tasked to make a program that is able to count how many instance among 13 praline class in a cluttered image.\n",
    "We must retrain our model from scratch and are provided with only a very limited number of training image (90)\n",
    "The score is computed using a modified F1 score (that take difference in number of predicted praline)\n",
    "\n",
    "For our approach we chose to make convolutional model based of the yolo architecture but instead we rewrote the network head to directly predict the number of instance for each class. We named our architecture yoco : you only count once. To train it we chose to make a synthetic dataset generator based of cropped praline from the training dataset pasted on top of the empty background that where extracted."
   ],
   "id": "9fe63d4b00129735"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Dataset & Preprocessing\n",
    "The original dataset offer 90 image that are 6000x4000 px, .JPG The image where taken in similar lightning condition and are relatively well lit.\n",
    "The inference dataset has the same properties.\n",
    "\n",
    "## EDA\n",
    "Image from the dataset look like the following with different background object, different miscellaneous object scatter around and a few praline.\n",
    "<img src=\"chocolate_data/dataset_project_iapr2025/train/L1000957.JPG\" width=\"600\" height=\"400\"/>\n",
    "\n",
    "Using the provided CSV we computed the histogram of number of chocolate per image and the histogram showing the number of instance per class to see how well the class are balanced. We also show how many individual instance of praline are available across the dataset and the maximum number of chocolate of each class present on an image.\n"
   ],
   "id": "e3f98282e3030554"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('chocolate_data/dataset_project_iapr2025/train.csv')\n",
    "\n",
    "# Calculate the total number of chocolates per image\n",
    "df['total_chocolates'] = df.iloc[:, 1:].sum(axis=1)\n",
    "\n",
    "# Print the total number of chocolates in the dataset\n",
    "total_chocolates_in_dataset = df['total_chocolates'].sum()\n",
    "print(f\"Total number of chocolates in the dataset: {total_chocolates_in_dataset}\")\n",
    "\n",
    "# Get the maximum number of instances per class\n",
    "max_per_class = df.iloc[:, 1:].max()\n",
    "\n",
    "# Print the results\n",
    "print(\"Maximum number of instances for each chocolate class in a single image:\")\n",
    "print(max_per_class)\n",
    "\n",
    "# Plot the histogram for total chocolates per image\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(df['total_chocolates'], bins=range(df['total_chocolates'].min(), df['total_chocolates'].max() + 1), edgecolor='black')\n",
    "plt.title('Histogram of Total Chocolates per Image')\n",
    "plt.xlabel('Total Number of Chocolates')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot the histogram for class distribution (excluding total chocolates column)\n",
    "class_counts = df.iloc[:, 1:13].sum(axis=0)\n",
    "plt.figure(figsize=(12, 6))\n",
    "class_counts.plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "plt.title('Class Balance Histogram')\n",
    "plt.xlabel('Chocolate Class')\n",
    "plt.ylabel('Number of Chocolates')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ],
   "id": "43b1082dfcccd78b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Instance extraction\n",
    "To make the synthetic dataset generator, we cropped manually the 583 praline present in the 90 image using a helper script to draw the box and save it in a new file. We made a second helper file to show the image and moving it to the correct folder after the operator write the class id thus making the sorting faster.\n",
    "\n",
    "Once the praline where cropped we spent many hours cleaning the background from the 584 pralines using paint or Gimp. That being done we made another helper script to re-orient, center and rescale the praline. The recalling factor allowed use to measure the size variation between the praline and thus know that the variation was +-20% and thus a single detection head would be sufficient. We also did the same with the misc object present and patched the hole in the background.\n",
    "\n",
    "Here are an overview of the cleaned praline :"
   ],
   "id": "e78cb5bd757d18e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Define path and ignored folders\n",
    "base_path = 'chocolate_data/praline_clean'\n",
    "ignored_folders = {\"MiscObjects\", \"raw_praline\", \"references\", \"Background\"}\n",
    "\n",
    "# Get valid subfolders\n",
    "valid_folders = [f for f in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, f)) and f not in ignored_folders]\n",
    "\n",
    "# Function to display a 6x6 image mosaic\n",
    "def display_mosaic(images, title):\n",
    "    fig, axes = plt.subplots(6, 6, figsize=(12, 12))\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    for i in range(36):\n",
    "        ax = axes[i // 6, i % 6]\n",
    "        if i < len(images):\n",
    "            ax.imshow(images[i])\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()\n",
    "\n",
    "# Process each valid folder\n",
    "for folder in valid_folders:\n",
    "    folder_path = os.path.join(base_path, folder)\n",
    "    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    image_files = image_files[:36]  # Limit to first 36 images\n",
    "\n",
    "    images = []\n",
    "    for img_file in image_files:\n",
    "        img_path = os.path.join(folder_path, img_file)\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            img = img.resize((200, 200))\n",
    "            images.append(img)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_file}: {e}\")\n",
    "\n",
    "    display_mosaic(images, title=folder)\n"
   ],
   "id": "6d8fa65999ba045b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Synthetic dataset generation\n",
    "\n",
    "To train our chocolate detection and counting model, we developed a synthetic dataset generator that creates realistic scenes by compositing high-quality, transparent PNG cutouts of pralines and clutter onto large photographic backgrounds. The generator is designed to mimic natural variations in object placement, orientation, scale, and density while ensuring dataset consistency and coverage across all 13 chocolate classes.\n",
    "\n",
    "#### Directory Structure\n",
    "\n",
    "The image assets are organized as follows:\n",
    "\n",
    "```\n",
    "../chocolate_data/\n",
    "├── praline_clean/\n",
    "│   ├── <ChocolateClass>/        # 1000x1000 transparent PNGs per class\n",
    "│   ├── MiscObjects/             # 1000x1000 PNGs of clutter (non-chocolates)\n",
    "│   └── Background/              # 6000x4000 high-res background images\n",
    "└── syntheticDataset/\n",
    "    ├── images/train/            # Generated training images\n",
    "    ├── images/val/              # Generated validation images\n",
    "    ├── train.csv                # YOLO-style count labels\n",
    "    └── val.csv\n",
    "```\n",
    "\n",
    "#### Scene Generation Logic\n",
    "\n",
    "For each synthetic scene, the generator performs the following steps:\n",
    "\n",
    "1. **Background Selection**: A random high-resolution background (6000×4000 px) is selected.\n",
    "\n",
    "2. **Misc Object Placement**:\n",
    "   - Randomly place 0–6 miscellaneous objects per image.\n",
    "   - Each object receives a random rotation (0–360°) and is scaled with ±20% jitter applied to base scale factors.\n",
    "   - Objects are not allowed to overlap but may touch. Up to 20 retry attempts are made to find valid positions.\n",
    "\n",
    "3. **Chocolate Placement**:\n",
    "   - Each of the 13 chocolate classes is assigned 0–5 instances per image based on a skewed probability distribution favoring 0 or 1.\n",
    "   - Each chocolate instance is rescaled (with class-specific base factors and jitter), rotated randomly, and placed while checking that overlaps do not exceed 20% with any existing chocolates (touching is allowed).\n",
    "   - At least one pair of chocolates (if more than two are present) is forced to touch to reflect realistic clutter.\n",
    "\n",
    "4. **Label Generation**:\n",
    "   - Labels are saved in CSV format compatible with YOLO count training, with each row representing a synthetic image and columns encoding the number of instances per class.\n",
    "   - Example:\n",
    "     ```\n",
    "     id,Jelly White,Jelly Milk,...,Stracciatella\n",
    "     1000001,2,1,...,0\n",
    "     ```\n",
    "\n",
    "5. **Scene Saving**:\n",
    "   - The final composite image can optionally be resized using a configurable downscaling factor.\n",
    "   - Image and corresponding label are saved in the appropriate `train` or `val` directory, based on a configurable split ratio (default: 80/20).\n",
    "\n",
    "#### Performance & Scalability\n",
    "\n",
    "- The generator uses multi-threading to parallelize image composition, utilizing `N-2` CPU cores to avoid overloading the system.\n",
    "- Progress is tracked using `tqdm` to provide live feedback.\n",
    "- The total number of generated scenes is configurable (default: 10,000), and all key parameters (e.g., scaling jitter, image size, split ratio) can be tuned easily.\n",
    "\n",
    "#### Result\n",
    "Using the technique descibed previously we could generate between 1000 ans 20k picture similar to the following.\n",
    "<img src=\"chocolate_data/syntheticDataset/images/train/1000000.JPG\" width=\"600\" height=\"400\"/>\n",
    "\n"
   ],
   "id": "a0b1c303d43350fe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Model Architecture\n",
    "\n",
    "- Motivation for direct counting (not object detection).\n",
    "- Description of YOLO-style architecture:\n",
    "  - Include diagram or schematic of model.\n",
    "- Explanation of output layer: `13 classes × 6 neurons`\n",
    "- Input size, normalization, padding strategy if relevant. (a precésier plus tard), number of parameters\n",
    "\n"
   ],
   "id": "ba5b1d66687464de"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Training\n",
    "- Data split train/val of 80/20 (data is not an issue anymore so this has little impact)\n",
    "- Hyperparameters (batch size, epochs, learning rate, etc.) 10⁻3 or it takes forever\n",
    "- Loss function & why softmax per class is used.\n",
    "- Optimizer & scheduler if used.\n",
    "- Include training loss plot.\n"
   ],
   "id": "10723580990b7599"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Evaluation\n",
    "- Description of the custom F1-score metric.\n",
    "- Evaluation process (on synthetic validation or original images?)\n",
    "- Show:\n",
    "  - F1 score per image and average.\n",
    "  - Class-wise accuracy/confusion matrix.\n",
    "  - Visual comparison of ground truth vs prediction on sample images.\n"
   ],
   "id": "51f408c232718136"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Inference on Original Images & Result\n",
    "- Description of final inference setup.\n",
    "- Load final model.\n",
    "- Parse original images & corresponding CSV ground truth.\n",
    "- Predict and compare with real counts.\n",
    "- Show per-image table: `image ID | GT counts | Predicted counts | F1`\n",
    "- Final F1 score on original dataset.\n",
    "- Example success cases (model does great).\n",
    "- Example failure cases (too cluttered, occlusions, etc.)\n",
    "- Insights about how well model generalizes to real scenes.\n"
   ],
   "id": "a4e5f47594424ba5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Discussion & Limitations\n",
    "- What worked well (e.g., synthetic scene generation).\n",
    "- What didn’t (e.g., failure on specific chocolate classes?).\n",
    "- Limitations of training from scratch.\n",
    "- Ideas for future work (e.g., more complex scene synthesis, weak supervision, semi-supervised learning).\n"
   ],
   "id": "d882d2decb42ce6c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Appendix\n",
    "- Journal de bord (dire ce quon as essayé et dans quelle ordre :\n",
    "\t- autoencoder (sans comprendre comment sa marche)\n",
    "\t- ultralytics yolo\n",
    "\t- classical ML\n",
    "\t- yolo v1 torch\n",
    "\t- yoco (custom head)"
   ],
   "id": "56ec9fa583f3c52b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Bonus\n",
    "\n",
    "Although we competed for the ML challenge, we also came up with a simple solution for the classical challenge by doing simple statistics on the training label only.\n",
    "We made a script to find the \"universal\" answer that would yield the highest F1 score in O(1) time and thus managed to reach F1 of ~0.4 by always predictive 1 for the number of instance for the 13 class. Although of little practical use we found it original, funny and stupid enough to deserve a mention here."
   ],
   "id": "770f47e4b42ca1aa"
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
